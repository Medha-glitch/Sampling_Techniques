## Sampling Techniques and Model Evaluation

### Objective
This project applies five sampling techniques (Random Sampling, Stratified Sampling, Cluster Sampling, Under-sampling, and SMOTE) to evaluate their performance on five machine learning models.

### Steps
- Preprocessed the Credit Card Fraud Detection dataset.
- Applied different sampling techniques to handle imbalanced data.
- Evaluated the performance of models using accuracy as a metric.

### Results
- **Logistic Regression** performed best with Stratified Sampling (0.993548).
- **Decision Tree** achieved the highest accuracy with Stratified Sampling (0.987097).
- **Random Forest, KNN, and SVC** performed equally well with Random Sampling (0.993548, 0.993548, 0.993548 respectively).

### Conclusion
Sampling techniques significantly impact model performance, and the choice depends on the dataset and algorithm.
