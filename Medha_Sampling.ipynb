{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##LOADING DATASET AND DATA CLEANING##"
      ],
      "metadata": {
        "id": "QZ6ldrUTOp84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sauNqqvnCc02",
        "outputId": "d8d4d3c0-bccd-4222-bc9a-62087130c15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      1  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       0\n",
            "V22       0\n",
            "V23       0\n",
            "V24       0\n",
            "V25       0\n",
            "V26       0\n",
            "V27       0\n",
            "V28       0\n",
            "Amount    0\n",
            "Class     0\n",
            "dtype: int64\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## 1) Downloading and viewing the dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from the provided URL\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Check class distribution\n",
        "print(data['Class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONVERTING IMBALANCED DATASET TO BALANCED DATASET USING SMOTE##"
      ],
      "metadata": {
        "id": "7rzz4x-_O1FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data into features and target variable\n",
        "X = data.drop(['Class'], axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Applying SMOTE to balance the class distribution in the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Displaying the class distribution before and after applying SMOTE\n",
        "print(\"Original Class Distribution:\\n\", y.value_counts())\n",
        "print(\"Resampled Class Distribution:\\n\", pd.Series(y_train_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acD9lEGbCh0Z",
        "outputId": "46d305bf-d93c-4706-fad8-c5b0304ec60d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Class Distribution:\n",
            " Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "Resampled Class Distribution:\n",
            " Class\n",
            "1    534\n",
            "0    534\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CREATING 5 SAMPLES, ASSUMING SAMPLE SIZES: 100, 200, 300, 400, 500"
      ],
      "metadata": {
        "id": "4KxnJBWgPG7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Creating 5 samples\n",
        "\n",
        "# Assuming desired sample sizes for different sampling techniques\n",
        "sample_sizes = [100, 200, 300, 400, 500]\n",
        "\n",
        "# Creating samples from the resampled dataset\n",
        "samples = [X_train_resampled[:size] for size in sample_sizes]\n",
        "samples_labels = [y_train_resampled[:size] for size in sample_sizes]\n",
        "\n",
        "# Displaying sample sizes\n",
        "for i, sample in enumerate(samples):\n",
        "    print(f\"Sample {i+1} Size: {len(sample)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24oluB1TCzpJ",
        "outputId": "7348613c-aa70-4055-aa93-d29f9dae6887"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 Size: 100\n",
            "Sample 2 Size: 200\n",
            "Sample 3 Size: 300\n",
            "Sample 4 Size: 400\n",
            "Sample 5 Size: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INITIALIZING DIFFERENT MODELS##"
      ],
      "metadata": {
        "id": "m7K8WNmQPznh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Defining models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVC\": SVC()\n",
        "}\n"
      ],
      "metadata": {
        "id": "X8jTSA4ZH-Vo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Splitting data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "6G52-824IFea"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SAMPLING TECHNIQUES##"
      ],
      "metadata": {
        "id": "BfKzkPJjJI94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE Resampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Under-sampling (RandomUnderSampler)\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Cluster Sampling (using KMeans to generate clusters, then sampling from them)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "X_train_clustered = X_train.copy()\n",
        "X_train_clustered['Cluster'] = kmeans.fit_predict(X_train)\n",
        "\n",
        "# Random sampling (Randomly sampling from the training set)\n",
        "X_train_random, y_train_random = resample(X_train, y_train, n_samples=len(y_train), random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "CNu0mYkzJevf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##APPLYING SAMPLING TECHNIQUE IN DIFFERENT MODELS##"
      ],
      "metadata": {
        "id": "eqGdlm-QOT2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = {}\n",
        "\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluating each model with each sampling technique\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "    # Random Sampling\n",
        "    accuracies[f'{model_name} - Random Sampling'] = evaluate_model(X_train_random, y_train_random, X_test, y_test, model)\n",
        "\n",
        "    # Stratified Sampling\n",
        "    accuracies[f'{model_name} - Stratified Sampling'] = evaluate_model(X_train, y_train, X_test, y_test, model)\n",
        "\n",
        "    # Cluster Sampling (Ensure that the clusters and features are consistent with the training set)\n",
        "    accuracies[f'{model_name} - Cluster Sampling'] = evaluate_model(X_train_clustered.drop('Cluster', axis=1), y_train, X_test, y_test, model)\n",
        "\n",
        "    # Under-sampling\n",
        "    accuracies[f'{model_name} - Under-sampling'] = evaluate_model(X_train_under, y_train_under, X_test, y_test, model)\n",
        "\n",
        "    # SMOTE\n",
        "    accuracies[f'{model_name} - SMOTE'] = evaluate_model(X_train_resampled, y_train_resampled, X_test, y_test, model)\n",
        "\n",
        "# Printing the accuracies for each model and sampling technique\n",
        "for key, value in accuracies.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RyQo1xTKumJ",
        "outputId": "cb1c49a7-9b4f-4aea-fba6-56ddbc65d701"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Decision Tree...\n",
            "Evaluating Random Forest...\n",
            "Evaluating KNN...\n",
            "Evaluating SVC...\n",
            "Logistic Regression - Random Sampling: 0.9806451612903225\n",
            "Logistic Regression - Stratified Sampling: 0.9935483870967742\n",
            "Logistic Regression - Cluster Sampling: 0.9935483870967742\n",
            "Logistic Regression - Under-sampling: 0.5741935483870968\n",
            "Logistic Regression - SMOTE: 0.8774193548387097\n",
            "Decision Tree - Random Sampling: 0.9741935483870968\n",
            "Decision Tree - Stratified Sampling: 0.9870967741935484\n",
            "Decision Tree - Cluster Sampling: 0.9806451612903225\n",
            "Decision Tree - Under-sampling: 0.5741935483870968\n",
            "Decision Tree - SMOTE: 0.9548387096774194\n",
            "Random Forest - Random Sampling: 0.9935483870967742\n",
            "Random Forest - Stratified Sampling: 0.9935483870967742\n",
            "Random Forest - Cluster Sampling: 0.9935483870967742\n",
            "Random Forest - Under-sampling: 0.7548387096774194\n",
            "Random Forest - SMOTE: 0.9935483870967742\n",
            "KNN - Random Sampling: 0.9935483870967742\n",
            "KNN - Stratified Sampling: 0.9935483870967742\n",
            "KNN - Cluster Sampling: 0.9935483870967742\n",
            "KNN - Under-sampling: 0.6709677419354839\n",
            "KNN - SMOTE: 0.7548387096774194\n",
            "SVC - Random Sampling: 0.9935483870967742\n",
            "SVC - Stratified Sampling: 0.9935483870967742\n",
            "SVC - Cluster Sampling: 0.9935483870967742\n",
            "SVC - Under-sampling: 0.6258064516129033\n",
            "SVC - SMOTE: 0.6709677419354839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PRODUCING RESULT IN TABLE FORM##"
      ],
      "metadata": {
        "id": "F5WQ04YMOKOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Defining the accuracies for each model and sampling technique\n",
        "data = {\n",
        "    \"Random_Sampling\": [0.980645, 0.974194, 0.993548, 0.993548, 0.993548],\n",
        "    \"Stratified_Sampling\": [0.993548, 0.987097, 0.993548, 0.993548, 0.993548],\n",
        "    \"Cluster_Sampling\": [0.993548, 0.980645, 0.993548, 0.993548, 0.993548],\n",
        "    \"Under_Sampling\": [0.574193, 0.574194, 0.754839, 0.670968, 0.625806],\n",
        "    \"SMOTE\": [0.877419, 0.954839, 0.993548, 0.754839, 0.670968]\n",
        "}\n",
        "\n",
        "# Defining the model names\n",
        "models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'KNN', 'SVC']\n",
        "\n",
        "# Creating the DataFrame\n",
        "df = pd.DataFrame(data, index=models)\n",
        "\n",
        "# Displaying the table\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxTTtB6yLw3A",
        "outputId": "84306372-d6f8-4e57-8c57-789fefeb42bb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Random_Sampling1  Stratified_Sampling2  Cluster_Sampling  \\\n",
            "Logistic Regression          0.980645              0.993548          0.993548   \n",
            "Decision Tree                0.974194              0.987097          0.980645   \n",
            "Random Forest                0.993548              0.993548          0.993548   \n",
            "KNN                          0.993548              0.993548          0.993548   \n",
            "SVC                          0.993548              0.993548          0.993548   \n",
            "\n",
            "                     Under_Sampling     SMOTE  \n",
            "Logistic Regression        0.574193  0.877419  \n",
            "Decision Tree              0.574194  0.954839  \n",
            "Random Forest              0.754839  0.993548  \n",
            "KNN                        0.670968  0.754839  \n",
            "SVC                        0.625806  0.670968  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HIGHEST ACCURACIES RESULT##"
      ],
      "metadata": {
        "id": "_knuvtJ8Rr-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the sampling technique with the highest accuracy for each model\n",
        "highest_accuracy = df.idxmax(axis=1)\n",
        "max_values = df.max(axis=1)\n",
        "\n",
        "# Combining the results into a summary DataFrame\n",
        "summary = pd.DataFrame({\n",
        "    \"Model\": df.index,\n",
        "    \"Best Sampling Technique\": highest_accuracy.values,\n",
        "    \"Highest Accuracy\": max_values.values\n",
        "})\n",
        "\n",
        "# Displaying the summary\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXAjLYsbMeim",
        "outputId": "c21303a1-cbfc-4c61-9b68-89671a4051cb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model Best Sampling Technique  Highest Accuracy\n",
            "0  Logistic Regression    Stratified_Sampling2          0.993548\n",
            "1        Decision Tree    Stratified_Sampling2          0.987097\n",
            "2        Random Forest        Random_Sampling1          0.993548\n",
            "3                  KNN        Random_Sampling1          0.993548\n",
            "4                  SVC        Random_Sampling1          0.993548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RlHe8jORpA5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
